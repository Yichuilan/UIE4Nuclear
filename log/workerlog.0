D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2349: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(parent)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API
  warnings.warn("pkg_resources is deprecated as an API", DeprecationWarning)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2349: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(parent)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\pkg_resources\__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('ruamel')`.
Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages
  declare_namespace(pkg)
D:\anaconda\envs\doip\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
[33m[2023-04-14 20:52:42,413] [ WARNING][0m - evaluation_strategy reset to IntervalStrategy.STEPS for do_eval is True. you can also set evaluation_strategy='epoch'.[0m
[32m[2023-04-14 20:52:42,413] [    INFO][0m - The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).[0m
[32m[2023-04-14 20:52:42,415] [    INFO][0m - ============================================================[0m
[32m[2023-04-14 20:52:42,415] [    INFO][0m -      Model Configuration Arguments      [0m
[32m[2023-04-14 20:52:42,415] [    INFO][0m - paddle commit id              :0e92adceae06b6b7463f2dc7790ffb0601730009[0m
[32m[2023-04-14 20:52:42,416] [    INFO][0m - export_model_dir              :./checkpoint/model_best[0m
[32m[2023-04-14 20:52:42,416] [    INFO][0m - model_name_or_path            :pretrained/uie-base[0m
[32m[2023-04-14 20:52:42,416] [    INFO][0m - multilingual                  :False[0m
[32m[2023-04-14 20:52:42,416] [    INFO][0m - [0m
[32m[2023-04-14 20:52:42,416] [    INFO][0m - ============================================================[0m
[32m[2023-04-14 20:52:42,416] [    INFO][0m -       Data Configuration Arguments      [0m
[32m[2023-04-14 20:52:42,417] [    INFO][0m - paddle commit id              :0e92adceae06b6b7463f2dc7790ffb0601730009[0m
[32m[2023-04-14 20:52:42,417] [    INFO][0m - dev_path                      :data/dev.txt[0m
[32m[2023-04-14 20:52:42,417] [    INFO][0m - dynamic_max_length            :None[0m
[32m[2023-04-14 20:52:42,417] [    INFO][0m - max_seq_length                :512[0m
[32m[2023-04-14 20:52:42,417] [    INFO][0m - train_path                    :data/train.txt[0m
[32m[2023-04-14 20:52:42,417] [    INFO][0m - [0m
[33m[2023-04-14 20:52:42,418] [ WARNING][0m - Process rank: -1, device: gpu, world_size: 1, distributed training: False, 16-bits training: False[0m
[32m[2023-04-14 20:52:42,419] [    INFO][0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'pretrained/uie-base'.[0m
[32m[2023-04-14 20:52:42,452] [    INFO][0m - loading configuration file pretrained/uie-base\config.json[0m
[32m[2023-04-14 20:52:42,454] [    INFO][0m - Model config ErnieConfig {
  "architectures": [
    "UIE"
  ],
  "attention_probs_dropout_prob": 0.1,
  "dtype": "float32",
  "enable_recompute": false,
  "fuse": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 2048,
  "model_type": "ernie",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "paddlenlp_version": null,
  "pool_act": "tanh",
  "task_id": 0,
  "task_type_vocab_size": 3,
  "type_vocab_size": 4,
  "use_task_id": true,
  "vocab_size": 40000
}
[0m
W0414 20:52:45.581063   548 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.7, Runtime API Version: 11.7
W0414 20:52:45.602492   548 gpu_resources.cc:91] device: 0, cuDNN Version: 8.5.
[32m[2023-04-14 20:52:46,728] [    INFO][0m - All model checkpoint weights were used when initializing UIE.
[0m
[32m[2023-04-14 20:52:46,728] [    INFO][0m - All the weights of UIE were initialized from the model checkpoint at pretrained/uie-base.
If your task is similar to the task the model of the checkpoint was trained on, you can already use UIE for predictions without further training.[0m
[32m[2023-04-14 20:52:47,081] [    INFO][0m - ============================================================[0m
[32m[2023-04-14 20:52:47,081] [    INFO][0m -     Training Configuration Arguments    [0m
[32m[2023-04-14 20:52:47,081] [    INFO][0m - paddle commit id              :0e92adceae06b6b7463f2dc7790ffb0601730009[0m
[32m[2023-04-14 20:52:47,082] [    INFO][0m - _no_sync_in_gradient_accumulation:True[0m
[32m[2023-04-14 20:52:47,082] [    INFO][0m - activation_quantize_type      :None[0m
[32m[2023-04-14 20:52:47,082] [    INFO][0m - adam_beta1                    :0.9[0m
[32m[2023-04-14 20:52:47,082] [    INFO][0m - adam_beta2                    :0.999[0m
[32m[2023-04-14 20:52:47,082] [    INFO][0m - adam_epsilon                  :1e-08[0m
[32m[2023-04-14 20:52:47,082] [    INFO][0m - algo_list                     :None[0m
[32m[2023-04-14 20:52:47,083] [    INFO][0m - batch_num_list                :None[0m
[32m[2023-04-14 20:52:47,083] [    INFO][0m - batch_size_list               :None[0m
[32m[2023-04-14 20:52:47,083] [    INFO][0m - bf16                          :False[0m
[32m[2023-04-14 20:52:47,083] [    INFO][0m - bf16_full_eval                :False[0m
[32m[2023-04-14 20:52:47,083] [    INFO][0m - bias_correction               :False[0m
[32m[2023-04-14 20:52:47,084] [    INFO][0m - current_device                :gpu:0[0m
[32m[2023-04-14 20:52:47,084] [    INFO][0m - dataloader_drop_last          :False[0m
[32m[2023-04-14 20:52:47,084] [    INFO][0m - dataloader_num_workers        :0[0m
[32m[2023-04-14 20:52:47,084] [    INFO][0m - device                        :gpu[0m
[32m[2023-04-14 20:52:47,084] [    INFO][0m - disable_tqdm                  :True[0m
[32m[2023-04-14 20:52:47,085] [    INFO][0m - do_compress                   :False[0m
[32m[2023-04-14 20:52:47,085] [    INFO][0m - do_eval                       :True[0m
[32m[2023-04-14 20:52:47,085] [    INFO][0m - do_export                     :True[0m
[32m[2023-04-14 20:52:47,085] [    INFO][0m - do_predict                    :False[0m
[32m[2023-04-14 20:52:47,085] [    INFO][0m - do_train                      :True[0m
[32m[2023-04-14 20:52:47,085] [    INFO][0m - eval_batch_size               :16[0m
[32m[2023-04-14 20:52:47,085] [    INFO][0m - eval_steps                    :100[0m
[32m[2023-04-14 20:52:47,086] [    INFO][0m - evaluation_strategy           :IntervalStrategy.STEPS[0m
[32m[2023-04-14 20:52:47,086] [    INFO][0m - flatten_param_grads           :False[0m
[32m[2023-04-14 20:52:47,086] [    INFO][0m - fp16                          :False[0m
[32m[2023-04-14 20:52:47,086] [    INFO][0m - fp16_full_eval                :False[0m
[32m[2023-04-14 20:52:47,086] [    INFO][0m - fp16_opt_level                :O1[0m
[32m[2023-04-14 20:52:47,086] [    INFO][0m - gradient_accumulation_steps   :1[0m
[32m[2023-04-14 20:52:47,086] [    INFO][0m - greater_is_better             :True[0m
[32m[2023-04-14 20:52:47,087] [    INFO][0m - ignore_data_skip              :False[0m
[32m[2023-04-14 20:52:47,087] [    INFO][0m - input_dtype                   :int64[0m
[32m[2023-04-14 20:52:47,087] [    INFO][0m - input_infer_model_path        :None[0m
[32m[2023-04-14 20:52:47,087] [    INFO][0m - label_names                   :['start_positions', 'end_positions'][0m
[32m[2023-04-14 20:52:47,087] [    INFO][0m - lazy_data_processing          :True[0m
[32m[2023-04-14 20:52:47,087] [    INFO][0m - learning_rate                 :1e-05[0m
[32m[2023-04-14 20:52:47,088] [    INFO][0m - load_best_model_at_end        :True[0m
[32m[2023-04-14 20:52:47,088] [    INFO][0m - local_process_index           :0[0m
[32m[2023-04-14 20:52:47,088] [    INFO][0m - local_rank                    :-1[0m
[32m[2023-04-14 20:52:47,088] [    INFO][0m - log_level                     :-1[0m
[32m[2023-04-14 20:52:47,088] [    INFO][0m - log_level_replica             :-1[0m
[32m[2023-04-14 20:52:47,088] [    INFO][0m - log_on_each_node              :True[0m
[32m[2023-04-14 20:52:47,088] [    INFO][0m - logging_dir                   :./checkpoint/model_best\runs\Apr14_20-52-42_LAPTOP-EMT0CBVK[0m
[32m[2023-04-14 20:52:47,089] [    INFO][0m - logging_first_step            :False[0m
[32m[2023-04-14 20:52:47,089] [    INFO][0m - logging_steps                 :10[0m
[32m[2023-04-14 20:52:47,089] [    INFO][0m - logging_strategy              :IntervalStrategy.STEPS[0m
[32m[2023-04-14 20:52:47,089] [    INFO][0m - lr_scheduler_type             :SchedulerType.LINEAR[0m
[32m[2023-04-14 20:52:47,089] [    INFO][0m - max_grad_norm                 :1.0[0m
[32m[2023-04-14 20:52:47,089] [    INFO][0m - max_steps                     :-1[0m
[32m[2023-04-14 20:52:47,090] [    INFO][0m - metric_for_best_model         :eval_f1[0m
[32m[2023-04-14 20:52:47,090] [    INFO][0m - minimum_eval_times            :None[0m
[32m[2023-04-14 20:52:47,090] [    INFO][0m - moving_rate                   :0.9[0m
[32m[2023-04-14 20:52:47,090] [    INFO][0m - no_cuda                       :False[0m
[32m[2023-04-14 20:52:47,090] [    INFO][0m - num_train_epochs              :100.0[0m
[32m[2023-04-14 20:52:47,090] [    INFO][0m - onnx_format                   :True[0m
[32m[2023-04-14 20:52:47,091] [    INFO][0m - optim                         :OptimizerNames.ADAMW[0m
[32m[2023-04-14 20:52:47,091] [    INFO][0m - output_dir                    :./checkpoint/model_best[0m
[32m[2023-04-14 20:52:47,091] [    INFO][0m - overwrite_output_dir          :True[0m
[32m[2023-04-14 20:52:47,091] [    INFO][0m - past_index                    :-1[0m
[32m[2023-04-14 20:52:47,091] [    INFO][0m - per_device_eval_batch_size    :16[0m
[32m[2023-04-14 20:52:47,091] [    INFO][0m - per_device_train_batch_size   :16[0m
[32m[2023-04-14 20:52:47,091] [    INFO][0m - prediction_loss_only          :False[0m
[32m[2023-04-14 20:52:47,092] [    INFO][0m - process_index                 :0[0m
[32m[2023-04-14 20:52:47,092] [    INFO][0m - prune_embeddings              :False[0m
[32m[2023-04-14 20:52:47,092] [    INFO][0m - recompute                     :False[0m
[32m[2023-04-14 20:52:47,092] [    INFO][0m - remove_unused_columns         :True[0m
[32m[2023-04-14 20:52:47,092] [    INFO][0m - report_to                     :['visualdl'][0m
[32m[2023-04-14 20:52:47,092] [    INFO][0m - resume_from_checkpoint        :None[0m
[32m[2023-04-14 20:52:47,093] [    INFO][0m - round_type                    :round[0m
[32m[2023-04-14 20:52:47,093] [    INFO][0m - run_name                      :./checkpoint/model_best[0m
[32m[2023-04-14 20:52:47,093] [    INFO][0m - save_on_each_node             :False[0m
[32m[2023-04-14 20:52:47,093] [    INFO][0m - save_steps                    :100[0m
[32m[2023-04-14 20:52:47,093] [    INFO][0m - save_strategy                 :IntervalStrategy.STEPS[0m
[32m[2023-04-14 20:52:47,093] [    INFO][0m - save_total_limit              :1[0m
[32m[2023-04-14 20:52:47,093] [    INFO][0m - scale_loss                    :32768[0m
[32m[2023-04-14 20:52:47,094] [    INFO][0m - seed                          :42[0m
[32m[2023-04-14 20:52:47,094] [    INFO][0m - sharding                      :[][0m
[32m[2023-04-14 20:52:47,094] [    INFO][0m - sharding_degree               :-1[0m
[32m[2023-04-14 20:52:47,094] [    INFO][0m - should_log                    :True[0m
[32m[2023-04-14 20:52:47,094] [    INFO][0m - should_save                   :True[0m
[32m[2023-04-14 20:52:47,094] [    INFO][0m - skip_memory_metrics           :True[0m
[32m[2023-04-14 20:52:47,095] [    INFO][0m - strategy                      :dynabert+ptq[0m
[32m[2023-04-14 20:52:47,095] [    INFO][0m - train_batch_size              :16[0m
[32m[2023-04-14 20:52:47,095] [    INFO][0m - use_pact                      :True[0m
[32m[2023-04-14 20:52:47,095] [    INFO][0m - warmup_ratio                  :0.1[0m
[32m[2023-04-14 20:52:47,095] [    INFO][0m - warmup_steps                  :0[0m
[32m[2023-04-14 20:52:47,095] [    INFO][0m - weight_decay                  :0.0[0m
[32m[2023-04-14 20:52:47,095] [    INFO][0m - weight_quantize_type          :channel_wise_abs_max[0m
[32m[2023-04-14 20:52:47,096] [    INFO][0m - width_mult_list               :None[0m
[32m[2023-04-14 20:52:47,096] [    INFO][0m - world_size                    :1[0m
[32m[2023-04-14 20:52:47,096] [    INFO][0m - [0m
[32m[2023-04-14 20:52:47,097] [    INFO][0m - ***** Running training *****[0m
[32m[2023-04-14 20:52:47,097] [    INFO][0m -   Num examples = 194[0m
[32m[2023-04-14 20:52:47,097] [    INFO][0m -   Num Epochs = 100[0m
[32m[2023-04-14 20:52:47,097] [    INFO][0m -   Instantaneous batch size per device = 16[0m
[32m[2023-04-14 20:52:47,097] [    INFO][0m -   Total train batch size (w. parallel, distributed & accumulation) = 16[0m
[32m[2023-04-14 20:52:47,098] [    INFO][0m -   Gradient Accumulation steps = 1[0m
[32m[2023-04-14 20:52:47,098] [    INFO][0m -   Total optimization steps = 1300.0[0m
[32m[2023-04-14 20:52:47,098] [    INFO][0m -   Total num train samples = 19400.0[0m
[32m[2023-04-14 20:52:47,119] [    INFO][0m -   Number of trainable parameters = 117946370[0m
